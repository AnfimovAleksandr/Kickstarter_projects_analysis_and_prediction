# Discalmer
Данный мини пет-проект создан, чтобы продемонстрировать навыки EDA, базовый feature engeneering, а также работу с различными моделями машинного обучения (базовые, бустинги, ансамбли, нейросети и табличные трансформеры), а также их оптимизация (GridSearch, Optuna).

# Краткое описание выбранного датасета и задачи 
Для проекта я выбрал датасет по [проектам Kaggle](https://www.kaggle.com/datasets/codename007/funding-successful-projects). Задача состоит в бинарной классификации успеха проекта по различным признакам. Выбрал именно этот датасет, так как в нём содержится текстовое описание проектов - в проекте также исследуются модели использующие текст для предсказания.

# Рекомендации по работе с проектом
Вся работа и исследование представлены в jupiter ноутбуке. Единственное ограничение - библиотека pytorch tabular может конфликтовать с остальными, так что тесты с ней лучше запускать отдельно.

Больгая часть оптимизаций моделей проводилась на ресурсах Kaggle для ускорения процесса (и за отсутвием требуемых мошностей).

# Краткое описание проекта

## EDA и Feature Engineering
Был проведён EDA данных, а также преобразование, обработка и создание признаков для моделей (более подробно в ноутбуке). Для моделей не использующих текст напрямую было сконструированно несколько признаков на основе текста.

## Выбор метрик
Исследуемые данные несбалансированные (провалившихся где-то в два больше), поэтому в качестве основных метрик взяты f1-score и PR AUC.

## Модели без прямого использования текста
Используются:
- классические алгоритмы: логистическая регрессия, деревья решений, случайный лес, наивный байес и knn (SVD не используется, так как слишком долго обучается на таком объёме)
- бустинги: XGBoost, LightGBM, Catboost

Для лучших моделей в своей категории подбираются оптимальные гиперпараметры. Лучшие результаты показали логистическая регрессия: F1-score = 0.818 и PR AUC = 0.884 при оптимальном пороге; и LightGBM: F1-score = 0.818 и PR AUC = 0.890

Далее исследовался Stacking и Blending моделей. Differential Evolution Blending привёл к небольшому улучшению: F1-score = 0.821 и PR AUC = 0.891.

Для интепретации важности признаков для лучшей ансамблевой модели была применена библиотека SHAP.

## Предсказание только по тексту и описанию проекта

1) В первой части работы строится TF-IDF по тексту и описанию, а потом обучатся модели из прошлых разделов. После чего также исследуется их блендинг. В результате лучшая модель имеет не слишком впечатляющие показатели: F1-score = 0.549 и PR AUC = 0.531 - всего на 10% лучше случайного предсказания с вероятностью 0.5.

2) Во второй части исследуется применение Embedding моделей (Word2Vec и SBERT) для той же самой задачи. На полученных эмбеддингах обучалась нейросетка для предсказания успеха. К сожалению, полученная модель показала себя немного хуже, чем основанная на TF-IDF.

## Комбинирование текста и признаков

Наконец, в этом разделе возможное улучшение при объединении как эмбеддингов SBERT, так и обычных признаков. На полученных данных аналогично обучается нейросеть. Обученная нейросеть показала результат немного хуже, чем лучшая модель до этого (блендинг).

## Бонус - табличные трансформеры

Дополнительно после завершения проекта я также исследовал возможность применения табличных трансформеров для предсказания. К сожалениб, к улучшению результата они не привели.

## Вывод по результатам исследования

**Лучшая модель:** Блендинг на основе моделей, обученных на нетекстовых данных

- **f1-score на тесте:** 0.821

- **PR AUC на тесте:** 0.891

**Ключевые факторы и рекомендации:**

- ***Количество бекеров*** - кол-во людей поддерживающих проект является без зазарения совести абсолютно центральным показателем в этой истории. На старте компании нужно набрать их как можно больше - это очень сильно увеличит шансы на успех.

- ***Целевая сумма проекта*** - маленькие проекты гораздо легче чаще преуспевают, чем крупные. Поэтому прежде, чем замахиваться на гигантские суммы нужно дважды подумать или четко всё спланировать

- ***Отключение коммуникаций*** - довольно очевидно, но отключение коммуникации - это красный флаг для пользователей, что с проектом что-то не так, поэтому ни в коем случае лучше этого не делать.

- ***Валюта для сборов*** - безопасный, но не самый эффективный - собирать в долларах. Однако если у проекта какая-та специфически страновая целевая аудитория, то лучше взять валюту этой страны - это увеличит шансы на успех. Исключение: фунты - проекты с этой валютой показыват себя хуже, хотя тут вероятно обратная зависимость и специфически Английские проекты направленные на внутренюю аудитории не востребованы.

- ***Дата запуска*** - судя по всему конкретный день запуска не имеет решающей роли, однако если всё же отталкиваться от весов, то лучше НЕ запускать кампанию летом и осенью.

**Итоговый самый безопасный вариант**

Маленький проект на 100 - 1000$ с сроком сборов в 15-20 дней, запущенный в начале декабря, с включенными комментариями и 3-5 бекерами.
